# Data Scientist

### Technical Skills: Python, SQL, Fortran, Pandas, numpy, sklearn

## Education
- Ph.D. Physics | The University of New South Wales, Sydney (_June 2023_)
- M.S. Physics | Karlruprecht Universit√§t Heidelberg, Germany (_May 2019_)

## Projects

### **Surf Myths and Car Park Chatter**
I only picked up surfing as a hobby recently, so I don't have the experience to know if what the more experienced surfer is true or just a myth. For this project, I gathered wind, weather and wave data to test various surfing concepts that you might hear in the car park or at the beach. I found answers to the questions of whether the surf is better in winter or in summer and if good weather = good surf or bad weather = bad surf. This project involved web crawling and scraping for data followed by extensive data exploration, feature engineering and visualization. You can find all the details [here](https://github.com/jcwons/SurfMyths-vs-Data).

*Tools: Python, Pandas, Numpy, Matplotlib* 

<img src="./files/img/Summer_vs_Winter.png" width="220"/> <img src="./files/img/Windrose.png" width="220" />

### Bayesian Optimisiation for Likelihood Sampling of Cosmological Data
In this project, I changed the Markov Chain Monte Carlo (MCMC) Sampler of the current state-of-the-art likelihood sampler in cosmology to Bayesian Optimisation. This allows for sampling complicated likelihood functions that have multiple local maxima. With the MCMC sampling method, the analysis was very cumbersome and took several weeks to complete. The new algorithm reduced the runtime down to hours and improved the accuracy. The project was published in a top-tier journal ([Publication](https://iopscience.iop.org/article/10.1088/1475-7516/2022/03/036) & [GitHub Repo](https://github.com/jcwons/BayOp)).

*Tools: Bayesian Optimisation, Gaussian Progress Regression, High Performance Computing, Bayesian Statistics, Fortran, Python, Bash, git*

### Fisher Forecast for upcoming Cosmological Data
I designed a Python program to forecast constraints for upcoming surveys. The computational expenses for this project were really high requiring several optimisation methods and parallelisation of the code on a high-performance computation cluster. I was able to reduce the computational expenses drastically by finding a statistical relation allowing me to approximate the most time-consuming step. Besides the programming, this medium-sized collaboration required me to manage with several stakeholders across different continents. The project was published in a top-tier journal ([Publication](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.108.L021305) & [Github Repo](https://github.com/jcwons/ksw_estimator)).

*Tools: Fisher Forecast, High Performance Computing, Parallelisation, Optimisation, Advanced Statistics, Python, Cython, MPI4Py*



